{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>meta</th>\n",
       "      <th>ids</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>folder</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d05-040</td>\n",
       "      <td>[Or, when, he, found, cock-fighting, going, on...</td>\n",
       "      <td>[d05-040-00-00, d05-040-00-01, d05-040-00-02, ...</td>\n",
       "      <td>[CC, WRB, PP3A, VBD, NN, VBG, RP, IN, NN, ?, N...</td>\n",
       "      <td>d05</td>\n",
       "      <td>d05-040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p03-151</td>\n",
       "      <td>[\", Isn't, it, ?, \", he, rose, and, smoothed, ...</td>\n",
       "      <td>[p03-151-00-00, p03-151-00-01, p03-151-00-02, ...</td>\n",
       "      <td>[*', BEZX, PP3, ?, **', PP3A, VBD, CC, VBD, PP...</td>\n",
       "      <td>p03</td>\n",
       "      <td>p03-151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c02-012</td>\n",
       "      <td>[Every, unnecessary, detail, ,, all, superfluo...</td>\n",
       "      <td>[c02-012-00-00, c02-012-00-01, c02-012-00-02, ...</td>\n",
       "      <td>[AT, JJ, NN, ,, ABN, JJ, JJ, NN, MD, BE, VBN, ...</td>\n",
       "      <td>c02</td>\n",
       "      <td>c02-012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>g06-047n</td>\n",
       "      <td>[This, remarkable, man, of, medicine, ,, whom,...</td>\n",
       "      <td>[g06-047n-00-00, g06-047n-00-01, g06-047n-00-0...</td>\n",
       "      <td>[DT, JJ, NN, INO, NN, ,, WPO, NPT, NP, NP, VBD...</td>\n",
       "      <td>g06</td>\n",
       "      <td>g06-047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>a05-029</td>\n",
       "      <td>[Sir, Francis, is, to, hand, over, to, Sir, Ri...</td>\n",
       "      <td>[a05-029-00-00, a05-029-00-01, a05-029-00-02, ...</td>\n",
       "      <td>[NPT, NP, BEZ, TO, VB, RP, IN, NPT, NP, IN21, ...</td>\n",
       "      <td>a05</td>\n",
       "      <td>a05-029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                               meta  \\\n",
       "0      d05-040  [Or, when, he, found, cock-fighting, going, on...   \n",
       "1      p03-151  [\", Isn't, it, ?, \", he, rose, and, smoothed, ...   \n",
       "10     c02-012  [Every, unnecessary, detail, ,, all, superfluo...   \n",
       "100   g06-047n  [This, remarkable, man, of, medicine, ,, whom,...   \n",
       "1000   a05-029  [Sir, Francis, is, to, hand, over, to, Sir, Ri...   \n",
       "\n",
       "                                                    ids  \\\n",
       "0     [d05-040-00-00, d05-040-00-01, d05-040-00-02, ...   \n",
       "1     [p03-151-00-00, p03-151-00-01, p03-151-00-02, ...   \n",
       "10    [c02-012-00-00, c02-012-00-01, c02-012-00-02, ...   \n",
       "100   [g06-047n-00-00, g06-047n-00-01, g06-047n-00-0...   \n",
       "1000  [a05-029-00-00, a05-029-00-01, a05-029-00-02, ...   \n",
       "\n",
       "                                                pos_tag folder document  \n",
       "0     [CC, WRB, PP3A, VBD, NN, VBG, RP, IN, NN, ?, N...    d05  d05-040  \n",
       "1     [*', BEZX, PP3, ?, **', PP3A, VBD, CC, VBD, PP...    p03  p03-151  \n",
       "10    [AT, JJ, NN, ,, ABN, JJ, JJ, NN, MD, BE, VBN, ...    c02  c02-012  \n",
       "100   [DT, JJ, NN, INO, NN, ,, WPO, NPT, NP, NP, VBD...    g06  g06-047  \n",
       "1000  [NPT, NP, BEZ, TO, VB, RP, IN, NPT, NP, IN21, ...    a05  a05-029  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# meta_json_data_path = '../../data/preprocessed/meta.json'\n",
    "\n",
    "# meta = pd.read_json(meta_json_data_path)\n",
    "# meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_length = 3\n",
    "\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# import random\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "# for sent in sent_tokenize(' '.join(meta.meta[0])):\n",
    "#     split_sent = sent.split()\n",
    "#     found = True\n",
    "#     while found == True:\n",
    "#         random_int = random.randint(0, len(split_sent)-1)\n",
    "#         target = split_sent[random_int]\n",
    "#         if len(target) >= threshold_length:\n",
    "# #             print(split_sent)\n",
    "# #             print(split_sent[:random_int])\n",
    "# #             print(target)\n",
    "# #             print(split_sent[random_int+1:])\n",
    "#             X.append(split_sent[:random_int] + split_sent[random_int+1:])\n",
    "#             y.append((target, random_int))\n",
    "#             found = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "meta_json_data_path = '../../data/preprocessed/meta.json'\n",
    "meta = pd.read_json(meta_json_data_path)\n",
    "\n",
    "random.seed(100)\n",
    "\n",
    "def create_data(data, save=False, out_path='../../data/processed/'):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    threshold_length = 3\n",
    "    iteration_threshold = 30\n",
    "    bad_lines = 0\n",
    "    \n",
    "    N = len(data)\n",
    "    for i, row in enumerate(data):\n",
    "        for sent in sent_tokenize(' '.join(row)):\n",
    "            split_sent = sent.split()\n",
    "            found = True\n",
    "            iteration = 0\n",
    "            while (found == True):\n",
    "                iteration += 1\n",
    "                random_int = random.randint(0, len(split_sent)-1)\n",
    "                target = split_sent[random_int]\n",
    "                if len(target) >= threshold_length:\n",
    "                    X.append(split_sent[:random_int] + ['<TARGET>'] + split_sent[random_int+1:])\n",
    "                    y.append((target, random_int))\n",
    "                    found = False\n",
    "                if (iteration >= iteration_threshold):\n",
    "                    found = False\n",
    "                    bad_lines += 1\n",
    "    print(bad_lines)\n",
    "    \n",
    "    if save:\n",
    "        np.save(out_path + 'X', X)\n",
    "        np.save(out_path + 'y', y)\n",
    "\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "data = meta.meta.values\n",
    "X, y = create_data(data, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../data/processed/X', X)\n",
    "np.save('../../data/processed/X', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.load('../../data/processed/X.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptb_iterator(raw_data, batch_size, num_steps, epochs, steps_ahead=1):\n",
    "\n",
    "\tdata = np.array(raw_data)\n",
    "\tdata_len = data.shape[0]\n",
    "\tnb_batches = (data_len - 1) // (batch_size * num_steps)\n",
    "\tassert nb_batches > 0, \"Not enough data, even for a single batch. Try using a smaller batch_size.\"\n",
    "\trounded_data_len = nb_batches * batch_size * num_steps\n",
    "\txdata = np.reshape(data[0:rounded_data_len], [batch_size, nb_batches * num_steps])\n",
    "\tydata = np.reshape(data[1:rounded_data_len + 1], [batch_size, nb_batches * num_steps])\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tfor batch in range(nb_batches):\n",
    "\t\t\tx = xdata[:, batch * num_steps:(batch + 1) * num_steps]\n",
    "\t\t\ty = ydata[:, batch * num_steps:(batch + 1) * num_steps]\n",
    "\t\t\tx = np.roll(x, -epoch, axis=0)  \n",
    "\t\t\ty = np.roll(y, -epoch, axis=0)\n",
    "\t\t\tyield x, y, epoc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
