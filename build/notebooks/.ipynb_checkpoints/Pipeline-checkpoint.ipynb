{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattevanoff/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/mattevanoff/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/raw/word_level'\n",
    "meta_json_data_path = '../../data/preprocessed/meta.json'\n",
    "word_level_meta_path = '../../data/preprocessed/word_level_meta.csv'\n",
    "word_path_mapping_path = '../../data/processed/word_path_mapping.pkl'\n",
    "X_path = '../../data/processed/X.npy'\n",
    "y_path = '../../data/processed/y.npy'\n",
    "\n",
    "X_wiki2_path = '../../data/processed/X_wiki2.npy'\n",
    "y_wiki2_path = '../../data/processed/y_wiki2.npy'\n",
    "\n",
    "bigram_model_path = '../../data/processed/ngram_models/bigram_likelihood_model.pkl'\n",
    "trigram_model_path = '../../data/processed/ngram_models/trigram_likelihood_model.pkl'\n",
    "letters_path = '../../data/processed/letters_map.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import boto3\n",
    "import os\n",
    "client = boto3.resource('s3')\n",
    "bucket = client.Bucket('handwrittingdetection')\n",
    "\n",
    "DATA_DIR = '../../data'\n",
    "\n",
    "\n",
    "def absoluteFilePaths(directory):\n",
    "    \"\"\"Walk filepaths\"\"\"\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            yield os.path.join(dirpath, f)\n",
    "\n",
    "def create_image_path(df, data_path, use_s3=True, s3_image_path='data/word_level'):\n",
    "    \"\"\"Create dictionary for mapping of word to data path\"\"\"\n",
    "    if use_s3:\n",
    "        files = list(bucket.objects.filter(Prefix='data/word_level/sample'))\n",
    "        all_paths = [f.key for f in files if '.png' in f.key]\n",
    "        \n",
    "#         all_path_endings = [i.split('/')[-1].split('.')[0] for i in all_paths]\n",
    "    else:\n",
    "        all_paths = [i for i in absoluteFilePaths(data_path)]\n",
    "#         print(all_paths[:10])\n",
    "#         all_path_endings = [i.split('/')[-1].split('.')[0] for i in all_paths]\n",
    "#         print(all_path_endings[:10])\n",
    "        \n",
    "    all_path_endings = [i.split('/')[-1].split('.')[0] for i in all_paths]\n",
    "    all_path_dict = defaultdict(lambda: 0, dict(zip(all_path_endings, all_paths)))\n",
    "#     print(all_path_dict)\n",
    "    df['image_path'] = df['image_name'].map(lambda x: all_path_dict[x])\n",
    "    return all_path_dict, df\n",
    "\n",
    "meta = pd.read_json(meta_json_data_path)\n",
    "word_level_df = pd.read_csv(word_level_meta_path)\n",
    "# print(word_level_df.head())\n",
    "all_path_dict, word_level_df = create_image_path(word_level_df, data_path)\n",
    "\n",
    "word_path_mapping = defaultdict(lambda: 0, dict(zip(word_level_df.token, word_level_df.image_path)))                              \n",
    "with open(os.path.join(DATA_DIR, 'processed', 'word_path_mapping.pkl'), 'wb') as f:\n",
    "    pickle.dump(word_path_mapping, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    \"\"\"Unpickle file\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# dataset \n",
    "# X = list(np.load(X_path))\n",
    "# y = np.load(y_path)\n",
    "\n",
    "# X_wiki = list(np.load(X_wiki2_path))\n",
    "# y_wiki = np.load(y_wiki2_path)\n",
    "\n",
    "\n",
    "# Language Models\n",
    "bigram_model = unpickle(bigram_model_path)\n",
    "trigram_model = unpickle(trigram_model_path)\n",
    "# Meta\n",
    "meta = pd.read_json(meta_json_data_path)\n",
    "word_level_df = pd.read_csv(word_level_meta_path)\n",
    "# word path mapping\n",
    "word_path_mapping = unpickle(word_path_mapping_path)\n",
    "letter2idx = unpickle(letters_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>meta</th>\n",
       "      <th>ids</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>folder</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d05-040</td>\n",
       "      <td>[Or, when, he, found, cock-fighting, going, on...</td>\n",
       "      <td>[d05-040-00-00, d05-040-00-01, d05-040-00-02, ...</td>\n",
       "      <td>[CC, WRB, PP3A, VBD, NN, VBG, RP, IN, NN, ?, N...</td>\n",
       "      <td>d05</td>\n",
       "      <td>d05-040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p03-151</td>\n",
       "      <td>[\", Isn't, it, ?, \", he, rose, and, smoothed, ...</td>\n",
       "      <td>[p03-151-00-00, p03-151-00-01, p03-151-00-02, ...</td>\n",
       "      <td>[*', BEZX, PP3, ?, **', PP3A, VBD, CC, VBD, PP...</td>\n",
       "      <td>p03</td>\n",
       "      <td>p03-151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c02-012</td>\n",
       "      <td>[Every, unnecessary, detail, ,, all, superfluo...</td>\n",
       "      <td>[c02-012-00-00, c02-012-00-01, c02-012-00-02, ...</td>\n",
       "      <td>[AT, JJ, NN, ,, ABN, JJ, JJ, NN, MD, BE, VBN, ...</td>\n",
       "      <td>c02</td>\n",
       "      <td>c02-012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>g06-047n</td>\n",
       "      <td>[This, remarkable, man, of, medicine, ,, whom,...</td>\n",
       "      <td>[g06-047n-00-00, g06-047n-00-01, g06-047n-00-0...</td>\n",
       "      <td>[DT, JJ, NN, INO, NN, ,, WPO, NPT, NP, NP, VBD...</td>\n",
       "      <td>g06</td>\n",
       "      <td>g06-047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>a05-029</td>\n",
       "      <td>[Sir, Francis, is, to, hand, over, to, Sir, Ri...</td>\n",
       "      <td>[a05-029-00-00, a05-029-00-01, a05-029-00-02, ...</td>\n",
       "      <td>[NPT, NP, BEZ, TO, VB, RP, IN, NPT, NP, IN21, ...</td>\n",
       "      <td>a05</td>\n",
       "      <td>a05-029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                               meta  \\\n",
       "0      d05-040  [Or, when, he, found, cock-fighting, going, on...   \n",
       "1      p03-151  [\", Isn't, it, ?, \", he, rose, and, smoothed, ...   \n",
       "10     c02-012  [Every, unnecessary, detail, ,, all, superfluo...   \n",
       "100   g06-047n  [This, remarkable, man, of, medicine, ,, whom,...   \n",
       "1000   a05-029  [Sir, Francis, is, to, hand, over, to, Sir, Ri...   \n",
       "\n",
       "                                                    ids  \\\n",
       "0     [d05-040-00-00, d05-040-00-01, d05-040-00-02, ...   \n",
       "1     [p03-151-00-00, p03-151-00-01, p03-151-00-02, ...   \n",
       "10    [c02-012-00-00, c02-012-00-01, c02-012-00-02, ...   \n",
       "100   [g06-047n-00-00, g06-047n-00-01, g06-047n-00-0...   \n",
       "1000  [a05-029-00-00, a05-029-00-01, a05-029-00-02, ...   \n",
       "\n",
       "                                                pos_tag folder document  \n",
       "0     [CC, WRB, PP3A, VBD, NN, VBG, RP, IN, NN, ?, N...    d05  d05-040  \n",
       "1     [*', BEZX, PP3, ?, **', PP3A, VBD, CC, VBD, PP...    p03  p03-151  \n",
       "10    [AT, JJ, NN, ,, ABN, JJ, JJ, NN, MD, BE, VBN, ...    c02  c02-012  \n",
       "100   [DT, JJ, NN, INO, NN, ,, WPO, NPT, NP, NP, VBD...    g06  g06-047  \n",
       "1000  [NPT, NP, BEZ, TO, VB, RP, IN, NPT, NP, IN21, ...    a05  a05-029  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_level_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c84800bdb0d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mword_level_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_image_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_level_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_level_df' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook\n",
    "import pdb\n",
    "import dill as pickle\n",
    "import os\n",
    "\n",
    "def absoluteFilePaths(directory):\n",
    "    \"\"\"Walk filepaths\"\"\"\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            yield os.path.join(dirpath, f)\n",
    "\n",
    "def create_image_path(df, data_path, use_s3=False):\n",
    "    \"\"\"Create dictionary for mapping of word to data path\"\"\"\n",
    "    if use_s3:\n",
    "        [f.key for f in files[:5] if '.png' in f.key]\n",
    "    all_paths = [i for i in absoluteFilePaths(data_path)]\n",
    "    all_path_endings = [i.split('/')[-1].split('.')[0] for i in all_paths]\n",
    "    all_path_dict = defaultdict(lambda: 0, dict(zip(all_path_endings, all_paths)))\n",
    "    df['image_path'] = df['image_name'].map(lambda x: all_path_dict[x])\n",
    "    return df\n",
    "\n",
    "\n",
    "word_level_df = create_image_path(word_level_df, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/processed/letters_map.pkl'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.join('../../data/', 'processed', 'letters_map.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.join('../../data/', 'processed', 'word_path_mapping.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates word_path_mapping\n",
    "\n",
    "DATA_DIR = '../../data'\n",
    "\n",
    "word_path_mapping = defaultdict(lambda: 0, dict(zip(word_level_df.token, word_level_df.image_path)))                              \n",
    "with open(os.path.join(DATA_DIR, 'processed', 'word_path_mapping.pkl'), 'wb') as f:\n",
    "    pickle.dump(word_path_mapping, f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07264511644073687"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_maximum_likihood_ngram_model(X, y):\n",
    "\n",
    "    y_preds = []\n",
    "    y_true = [i[0] for i in y]\n",
    "    OOV_token = 0\n",
    "    for sample_index in range(len(X)):\n",
    "        index = int(y[sample_index][1])\n",
    "        target = X[sample_index][index]\n",
    "        try:\n",
    "            prev_word = X[sample_index][index-1]\n",
    "        except:\n",
    "            prev_word = '<bos>'\n",
    "        try:\n",
    "            prev_prev_word = X[sample_index][index-2]\n",
    "        except:\n",
    "            prev_prev_word = '<bos>'\n",
    "        pred = trigram_model[(prev_prev_word, prev_word)]\n",
    "        if pred == OOV_token:\n",
    "            pred = bigram_model[(prev_word)]\n",
    "            if pred == OOV_token:\n",
    "                pred = 'UNK'\n",
    "        y_preds.append(pred)\n",
    "\n",
    "    # compute accuracy \n",
    "    n_correct = 0\n",
    "    n = 0\n",
    "    for pred, true in zip(y_preds, y_true):\n",
    "        if pred == true:\n",
    "            n_correct += 1\n",
    "        n += 1\n",
    "\n",
    "    return n_correct / n\n",
    "\n",
    "# evaluate_maximum_likihood_ngram_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1105255770629442"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_maximum_likihood_ngram_model(X, y):\n",
    "\n",
    "    y_preds = []\n",
    "    y_true = [i[0] for i in y]\n",
    "    OOV_token = 0\n",
    "    for sample_index in range(len(X)):\n",
    "        index = int(y[sample_index][1])\n",
    "        target = X[sample_index][index]\n",
    "        try:\n",
    "            prev_word = X[sample_index][index-1]\n",
    "        except:\n",
    "            prev_word = '<bos>'\n",
    "        try:\n",
    "            prev_prev_word = X[sample_index][index-2]\n",
    "        except:\n",
    "            prev_prev_word = '<bos>'\n",
    "        pred = trigram_model[(prev_prev_word, prev_word)]\n",
    "        if pred == OOV_token:\n",
    "            pred = bigram_model[(prev_word)]\n",
    "            if pred == OOV_token:\n",
    "                pred = 'UNK'\n",
    "        y_preds.append(pred)\n",
    "\n",
    "    # compute accuracy \n",
    "    n_correct = 0\n",
    "    n = 0\n",
    "    for pred, true in zip(y_preds, y_true):\n",
    "        if pred == true:\n",
    "            n_correct += 1\n",
    "        n += 1\n",
    "\n",
    "    return n_correct / n\n",
    "\n",
    "\n",
    "evaluate_maximum_likihood_ngram_model(X_wiki, y_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical <TARGET> @-@ playing game where players take control of a military unit and take part in missions against enemy forces .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(X_wiki[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['role', '13'], dtype='<U16')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_wiki[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "def ngram_backoff_model(sample_index, X, y, OOV_token=0):\n",
    "    # get index and target word\n",
    "    index = int(y[sample_index][1][0])\n",
    "    target = X[sample_index][index]\n",
    "    # get previous word(s)\n",
    "    try:\n",
    "        prev_word = X[sample_index][index-1]\n",
    "    except:\n",
    "        prev_word = '<bos>'\n",
    "    try:\n",
    "        prev_prev_word = X[sample_index][index-2]\n",
    "    except:\n",
    "        prev_prev_word = '<bos>'\n",
    "    # model preds \n",
    "    pred = trigram_model[(prev_prev_word, prev_word)]\n",
    "    if pred == OOV_token:\n",
    "        pred = bigram_model[(prev_word)]\n",
    "        if pred == OOV_token:\n",
    "            pred = 'UNK'\n",
    "    return pred \n",
    "\n",
    "\n",
    "def teseract_baseline(sample_index, y, word_path_mapping, letters, tmpdir='tmp/'):\n",
    "    img_width = 256\n",
    "    img_height = 100\n",
    "    # gets image from sample index\n",
    "    img = word_path_mapping[y[sample_index][0]]\n",
    "    im = Image.open(img)  # img is the path of the image \n",
    "    im = im.convert(\"RGBA\")\n",
    "    im = im.resize((img_width, img_height))\n",
    "    newimdata = []\n",
    "    datas = im.getdata()\n",
    "\n",
    "    vals = 255\n",
    "\n",
    "    for item in datas:\n",
    "        if item[0] < vals or item[1] < vals or item[2] < vals:\n",
    "            newimdata.append(item)\n",
    "        else:\n",
    "            newimdata.append((255, 255, 255))\n",
    "    im.putdata(newimdata)\n",
    "\n",
    "    im = im.filter(ImageFilter.MedianFilter())\n",
    "    enhancer = ImageEnhance.Contrast(im)\n",
    "    im = enhancer.enhance(2)\n",
    "    im = im.convert('1')\n",
    "    \n",
    "    if not os.path.exists(tmpdir):\n",
    "        os.makedirs(tmpdir)\n",
    "    save_img_path = os.path.join(tmpdir, 'temp_img.jpg')\n",
    "    im.save(save_img_path)\n",
    "    \n",
    "    text = pytesseract.image_to_string(Image.open(save_img_path),\n",
    "                config='-c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyz -psm 13', lang='eng')\n",
    "    \n",
    "    os.remove(save_img_path)\n",
    "    os.rmdir(tmpdir)\n",
    "    return text, len(text) \n",
    "\n",
    "\n",
    "    \n",
    "def get_ocr_model_pred(sample_index, y, word_path_mapping, letters):\n",
    "    ocr_pred, len_pred = teseract_baseline(sample_index, y, word_path_mapping, letters)\n",
    "    return ocr_pred, len_pred\n",
    "\n",
    "def get_language_model_pred(sample_index, X, y):\n",
    "    pred = ngram_backoff_model(sample_index, X, y)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def get_pos_tags(sample_index):\n",
    "    return []\n",
    "\n",
    "def weight_features(sample_index, X, y, word_path_mapping, letters, weights={}):\n",
    "    ocr_pred, len_pred = get_ocr_model_pred(sample_index, y, word_path_mapping, letters)\n",
    "    lm_pred = get_language_model_pred(sample_index, X, y)\n",
    "    pos_pred = get_pos_tags(sample_index)\n",
    "    \n",
    "    print(ocr_pred, len_pred, lm_pred)\n",
    "#     final_pred = ocr_pred * weights['ocr_pred'] + \\\n",
    "#                  lm_pred * weights['lm_pred'] + \\\n",
    "#                  len_pred * weights['len_pred'] + \\\n",
    "#                  pos_pred * weights['pos_pred']\n",
    "#     return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hax 3 first\n"
     ]
    }
   ],
   "source": [
    "weight_features(sample_index, X, y, word_path_mapping, letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=132x51 at 0x11BF3FCF8>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_index = 102\n",
    "Image.open(word_path_mapping[y[sample_index][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_language_model_pred(sample_index, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#&\\'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = list(letter2idx.keys())\n",
    "letters = ''.join(letters[1:-2])\n",
    "letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hax', 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teseract_baseline(sample_index, y, word_path_mapping, letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAABkCAAAAABMC7FCAAAanUlEQVR4nOWdaXccx3Kmn6y9ekFj4SKNPZ47/v+/aM4sHtu6lEgC6LX2qmc+FEiCAhqkxvdKPkfxTTqJ7MjIWN5YshgMWZv1mbdFyhBPxPy5KPpwcUhHLn/+h4hdEsKf7fyE1x8gHsL6p9cN0yTpH83R70wBg4G8vfiXq+0ypf+zCSC6OpRZytTsf5wu0+Ptn+38BCD5cHOxpcsEwx/N0O9NkZcO/zxuYeEH2P/R/PzulIzb3FBiKILhuDkt/2iOfmdKIpNQ9Cw4hEr6P9v5iUI4XdzeUCdhcRX68Y/m53en5GjIl6wP+VAFg03xR3P0O1O0Ij0VHw+r06I0/zn5s52f4Id/6MLNbXNVQzG1fzQ/vzuFLiUYKOsf3wWz9s8XBSbu0tyo5mfiuA3+0Qz93hSsSwJZR9EQpsCfTQJRUyYVRtjCZcg8sZM/kSuIirZdLPdNVPgD92+6sPxl44ec+z+asd+LokM+cfrxv009JxbvvTEhuparP5qx34uCMCT1AlZHePURFx+ismqu/2jGfi8Kp0WfxmPZJy1XbRUxCVPEnyYcRoth/GkMp7GFbUU5TTk/R+//NOcnVCXQr9t8ZADSYbcGqMs/lq/fjUJVdlFCMMQjRT9CmJg0+aMZ+70oKuss3GNIp0A8kSFxiLsnC08wwJGOXhyhh76ugQN1/duRw6f95n0YBsYBatjTMrQAHRVa09H//fL0iGSIr4Yw9Hp1KunS5bvRcfFk4ZKu71lN2V0ffgkxpDRJWVYda7Ly3/Lf+sOf9mvSj01aVklNSBiTsblo87rJ6emzJmcberI+Hf5+/YqPOtgpbwILXmVwlVY2vb+mvtO922r+r6Mf9FhrpzpVT5Z/kx72c6uH0d6p64eTrZX2OthNrR7cuj/+9s2/n6Ib7u0Hwvg+j6u3H7ssvus7nrnQEDGVbPKmH+CwvHu13S6hS6udp1D+dhV92I/N+NcVJG1Ik2Fxm9HDODQ9ITS0smGdcOL4N7jr56k/6s7a6gcSSC6ICLp/emH6offUTvrOo+O8pLXt1L7rfqvkP+3XWmkzdP3YWKnNaGWvlVrX7vw/Wv/27b+b0Kl1p0GWGZAQQnrv+OuFzaR6cOpQijB7iZiiwY+TT03mG/RpP997Z67FcXFcG1W5wWpR7XZ26s/WHobW4T980HPE3mrU4TQN5YENLGH1S/qcyO+1d4eCTCCvT1lHU/bXVVH/9p+e9/MjIu16t+KwIgZ5M7z7Qa3sHW0cdfz/2P/7CEc/WqtSQhJYsuKpAli5tXO3FlJJiEkhC1CQIr/5hz/tB1EMawAKFkBawDUklDEjI/Yn2//4Sc/QZ87D1BKIiOCCqnS0Uh3dqqMHtZM+JHA96wkhjykoicgDWT/1ntSD9nrWc09Ora3T5HCqy5j9BSkbngBPMW5ipmJ0HB2no033EHP+PgKYzOpXAMkNVzenuzsHdfCk3tvqnTvcgBE//cgF6RpiCGyAwvj9xve206hd9Y0Lu1eHoxc93FyQwOUz3jnLSSmAKBVbdfJ2+Js7gy+6u+0S4lVJBHSo/Z022ux1e7IVoRTgL1AugZgkhSxjQcaaKbS6da/deZ/YN6OVViIsc1gBhCdxd0VYs97AFUF6/dC49bc72+8WwEEMRUYMcRRNHLZqe/TkUKtjVxF8TcIP5HANZZFCSb6EmCUxmB3caj/60kX1J3etysSSpMgWJK/gSe6RzX3qAGvELlJbf/pbn/+RBuylgRvSa9YUOowOOnnUj52ssYQlC8olCxYp5AsWEC+JMrKsLAiX6dSe7D+8cFNHrbQmW33qwSQR8TNI9zUUkGYQWIhNS9/6N48Gj9x3crzhihWBPHm/fmdlrV0/WWnbx8CCuAwZ2xXcskob0uPldUxyM19WkR/Qg+rUnPvB6d7pgz9varjhLfGGNaRPk88LVpSQQ7QW1pSjvX9HAfRDLx9/IM4JEde8/kXbZmutH41Yxe3FkpB2Ca9SjmWR3yfblcB1RMq6yMnhbRTv7Gcvd5Zq5ZpldgmsiCAts6cKEF8A8TVxHEh4PWAGw+5vff5HGlCLBQESSBD7k+5Uj1fSEjLGArDp0VOv3neOwhURJBRlgGm9s3Pr2eyomuafjSCks7cjgacVqCjwmpyINcsAS9rQpt7+3QTQ21j5iCGpG/cOYvLJScWI0damtbfq9UPpxBzEY4jKgiw92b+gqb1jM58wj1iRJMRkFETED2AgJoOQJAuWEWkyJ2ZCWfSMWdfaaXsebww2Q2vn6ND4XrvWzpOe7KwcO09ObmcXd2f3BQeM1mM63HxWSXXa2eqeiiWxsXgft9uuHW1G7/X+5MlYKCkg2pSQSa31C+D9X7QwFGsoAhDB0VlkDFvtHKwdRUqiQAYLkozrf1sCYu9+svYs3ugrdevYNJU6YbxLMC6L9hWyMMe8ZdD9qI5fTODuoPcbPjulGKdWaTcb3gAkYqyDk/fzAfvlvV3fKSnhBtKSjEtb2vOqeu+BBEgWwJokNJN4RDoT0SBGMsVGESxICi6AECV1lt10NHiyP4s3Jr1tbNWd2T2uekyECcJ0Eb8P1IHXgtTeN8NnATT2Ml2Nn8JSJBNi1JJCGpZRaO2s3lt3s6v/4O3MQWpckhP/CAvAVj+cVQDrU+IM/l/HIK5+mjyqY3ew8V7HaWzVRoUrSCiiBbDehV0cr7LdZvR4Dm+Mw72djtM7O+SKHyCLkyUxcUy2FDIJyAK2tl804J2d0zH9BEySOPOjpnLJ6hWINe61tu8dnRx0Oznh3juTRbqAJSwSmrvppewFWD74DbLGWsex7+5VP/3ZZOVBekdxA8ANkJPnh/iw5md8AW/sm9a2N6SLJUjIWBD4C6zoC26M53HAU96UX6VxdyrjZ2iaidBRQERdxtVcoBqHnZ6sOj1WDxzvL2ogJUq4oA+mLyQt+62vIYdlSHmNTK1drd42w/DeZjxqPV9so0zuGTGP4O2Syw9Eq5igZ/FG38/VA0R4BaQZeQ6QUeQsSda8hiFPWbq6/yyA42DjoJ+Sk0vSBimyuEXenqYweLpzO4v8Vv9tUne6u7dqtH/NG9KSFUum9qW0jcCyJAM2eLS3FY8fnewcnDpPnpya+th69KROsRxWwIolGIyAs3ij69tejiv4gU0CV0BEKIizHJJ8G5mPcIEJfqUB0zSOw+f0dEGUddCSUszLbic9aOXBYda902BV652GNiGDlJIFhmk6e/x6iNIUCkK0JsbBlnGcRt/p1m7QqddBR60n+zs5eQwlq4yYFSmU1GV9Fm80do69CDnkOSmEkMylBhJyCBg1i30p8qSSAQUZxAsKYgHzUV5KwiprrRQCpMQRnaezq7tPnedXJDH6zYLHw4FiZ2OUuCJZIN73sx18TWPtED0GVKQRpATgkhBEmutdMSIO/dNSDgBv4QcgJl1jtvX+PIedY+9R6SLCdZxEmPBCNvjzjVwmGRkhTe/8ZsnrQaWPfSS8JoT2hiPg4H5w++vl9zp5iD4PulzCAl5BiFiTAhfD4qh+dNL+aS0L1jNEJawWILM5n2WwHW2nzmE63qSfBB9eKJENQgFkRDnKt4qen5ya/uuwE06LiJTIEHF4enzVE9HqUV0/5VUM81h4If1ENyxuxbu9/cennFYbWMGyXADjBaL7+/PY3lEnT3SyZZUlXEZQn9fpShKuFrAkBf2Osve+aW13o4n5u7crhtVhDRlVqR+f2uatnh7nFKsI0joW5cQUbHef1lX6VAAlefIgudlIvdMXbPTkth/HWt+n3ABkgf/O+oXzQAnXsGCxULXx+Jwxz/QJ2IwO3XjcvINrlsSLiDy+86nqHG1TQv554PM16fLB8jFMdtWoXTuo4zi2+2d8QAh5midLygKkrdXu/dnjTFtt81bc53DxkDIt370ggCU3gSQBartvtb4+Q9tBR6d0QFwAgYl+eqo6w3X91cunjOSkit5r5y9rD31rY3Xw+IwGSHsBATJIqqV23r1Y49zqwbF3MD6SswhpwdPg8oVqEuB1BAX/5OBOuxcs7FNy43b0o33sD8QlxlCWwzOQuz29v5Avzd3XKFLVW23q0a13tT3W6v7k6RkBFKSQp0SLKLZrJh2q82HwaDdY6+myZ12QEUGcPtNYeKDBiPwCSFhK71TZ2nXnveBDetvZN/ZzVyZKgBh4TnA74XEYXMen1VYjh+ZTy29vr3+d7foZAUgSyCjhZsTWfvq+zlTfIFkGrFfY+AAPniyTqqBkA2+xcWqGF9oIn+lzY0aIyEhTMHkanE6TuRAoYUXC5v6SKeobh53uPP5a4E8E0OKGZEVECdiEqbV2OA/tHmjQ+geA5JLZBOrJZ5KV0SlaUEAWRbsw2I8PYvkm3c+tNFjlkJGvwLsnq0aPUFxSZF4AsLzLJ0xO6t6dvza5pxowLCFbAWVghoB331WL3PsRoxWzgWtrOz5fFoAV60vKmFx0W4/1S05gpk/N1FsNXHJxQb4aeUZ1ts6gNBBuN1POkrfs6JYtjUfHXzvdJwLoC5cxrENUkLL35Hvrp4J+QpOb4xrIKXP4x9766FA/c7F3O/ECViAfnT5+Qv4v06d2+tUhYsMClgSeQ5zDUdI3RBn8BSBNyXKKrbXbucj5Vdh9IoDuPuHiE5DasM304POQ6ys6TI38fE0O2QJq9NbnVXseKMriSxYMkY52LxRQPh9scOzVrVJsKEnxGQFUvY0V8yPo/lKkKHsA0e4J8HoigMEqWYVAVKYUifrv6lyeeZm6sckvQ8oFrIjVnb1P4/ShnUyvWGyADuPT0dP4zEDGE3oYqeno48Wc5EQ815Y+ufW4iAsuc1bZXN5IrpFoO3L3ZN7gyQbjsbsEyoyoLCja1aT/PnzbSU2VniAUEHhNZqt7f366sLGiI4ENxSUu0mbRfocCaFt1Ojpi4FVYR6zhOd9cN9odVsAS0/eXr72a04888em8wVMJdpsDS0gg5Sp2b9t8jwLoiCsS1iQl5RjbOnVPbbv3INGCEGXMjiDU03kk/JmO2uvBfjSaHzWUVMtn+Dpp1V6JJCUP9fwsIU0pusnh1+n3UwFUo3suoCAUkFvb332PBahDBDEkEJ/FD5MHPw5AiGFBEn/S47q1eqGYWg9Hj72KDyeifAlwjpZwwZjIFXkJa8ijYRqGweZRUHvqBD1FzVsIFwR4M3Cv1t8RB/vb43LgFRtYkVbn8MNptDIRLme9ZMXKsR5rT7Uvq9ovo03rQFiVc3r7z4fT6uxqerKCm4jUCOKEkG1RB++0Pw+ExmlCFlFKiDfAoG3zHVBwNMh0Q0mRkiwGz+KHu6HqIIbXFPNMUIKROj6Da778lQetBqNYEqIfWa04PYuFZ5qL6q/ICmC1gAsWF9BO/qKnL1HtGSXaS8YiWkCU4+bWlzs9n+g03rUlN/wA5KzP4Ye21szbdREXSUIUJL5Ujx6q0dHziHPy5MlBVgvCDQVpyUsas998QGIuiXvYcAlYTnPp90vYecYE9EBJYAnZmujW1u8AApW6gTyQhB/jZDqHH6bJeuzkfQ5vICImTkB7/cnzHaW60b20Ye7fXrCIklP+QnCqBi2ZFuQFi3gewwp0ZWv/uGL5VAPuGkxYEKVrYEIn//qt46v682Z3/ZCIrjmHH0aP6vuFXEGygfSKUuRo592LSdHtpJkb5po6IX9pOG3v1J4Gcq5jEihI1lxidHBSvyCh57Y4mM4AIr54hf1RvyNMWSuSJ5D9Iz/0L+CHXaVyxzKBfEkMidlw86G1PW8BzXsN79dABMWaixXsHV6opb3r9ShSRg/6zH8FsXH/ogn8pJCRkxCTZ4291bd9wDg5rnZEPOjAOfwwTdobeiMhIU1hIYsqqcXxBZtuIltJyAmXEMHSMJ4HaGOjVJpDRryAFYuMPK8Hv/LNTzWgHm0ePZ9sZfLjAwR7yU13c4hekQKXVd55et5HTYO90i+RDMgjWNWFjHRopdNk1X3Snv38v/Bg4A3EhBySkMxY8zNt9eTOznb4KmqN+cQFJYEkJY94vdP+i+CehkEPuvhSVs48jWrj3u6lC7oV5W0EKUVBqBwcTk+R4K7T1ioSSwKEErhkA6br/uow2djs1aq3nZxa3ymNnQnkvMnKFaRlxAqn3eMWXO14nAXhowoW3SHPuSTJY4giLv63w+FR8HwigLrrD7r+rAGHWu3mLPL9S9XrpjduKVkBUSk6PozY/FrCfzX/IPerAVnmxMTIhTRgNBx3qrtBm3EuYKS/KCswjVNSWCwDxcMbhS8nnT5aO3y0tbn1Szjt9bhybkZfhyhlGZ+0Pa8Bk7rFz2NLP97rQYfDnLOeddMn7cdrAoQIfqQdx53PlK3r8ReP9xeYiCRAfMOaFUSUBDLL/WH6dxtPvdL2zOtMVxGQ8U+BhC60epyq4fNdTid3bnXUzvth/MLXB6uCZBWvCeTQIMcvivnUB+x0TB89oZa5hd/N13eWflaqDBZclGCqbp8DgqNNfloKmIGBNVDM3jPEEeSRP3SFWIAhWkAxj1BFG6I4hzJYWHn/lTPrFePuvrVtvkqu36vDHuCGEq7YHLuXnGBr05h9EUCstb7Tnd7354HH4CAF1zlQFEvcjU7dUyx8bGs9bRg2UsxNkug1sORH4pCFCCI+XO3woso7PiUMa64fxmoL+/HeWn1XHb5kdU09MZjMrLRfGN07eXJybcRm3uxmyQtOsJtrz+VjDXivjrPLPWsCY5s7JMBqCWChw6dK3q9WekTW5BEUEYsF5AuSdK50swDecHUF8Jo0ZCtWLAkplzlRuTyV4qj9e7X5Aur6zComOWLf9o+d1f3IlDYsE4A3GyLKl6Bwr3W/2D8aXbTVk72Hl+s201iFgiQDlryqag9Oz+CHuW2IXAyYkeaQF/MHrRZEZDMEATJWMXlYwoIFRSCHmAH94Mne3v4x0O4cZkzdj3aPolU3OszheJckZfyQSRudFYCOX39GQia78/1+O/vKxr1aQFRCCRdnQepw0uFYRqlkEJEkxDkLQkEM6dnByRgoYYz1Xvc21ra149Q5Dnai7VwpGRyeVVTgah5hyCOHk/9X+2fa4x7s7y4Pn3srqVgN5+sBjQ6Hoj5cHAh4AVzELKMXvOXudHKkC2Sr5W0BOSnRAl4nYcPZ0VmuMkxq+3/X2qH21E9zwfJ+81H3NlzGJJcUok+zynF/Z8KKB4Sz8HDVVFP3zIBE1+jj8fXoNM/EnKP+qNs3o9qugPhhsPOswFonu2ZJvxDWSUQhMYRr0htYnRuexm00dG9+cXJ7OHp01l5utZP9pfi/yhWAtj8/Nz1UtPNgPz8s2VTr7awlz/iAO0+PoPCiR+/Om/84WD0sT+F6yTri5qUnRLWHUTWW7i3txT00kVEMRNGGc+Pzci1utTumNs3Mefehs8HjgEh5QX6zAG6vn/nd273Ea1jOnfM7dfCXZ5BgY/31h1Q81t8qCmOMEW+BJKPAxfkkZWhsKpvb7aC3Dns96Wm0R2B97gEFt2JTjFU6OfQ6eR//cmWQbmPhbNxcA678+NRntX46V3Sdc53G4zza/8xdNZX66tPvroi1OZ1NAgbvJRQPnZqw2BCjL4wH2Dtq76umxyFMbuVg7GDWxZ59QhMjddzT6MFWRpQdI3KEBSNwEQe4hPUzhaXGXbmVJIXZxY5477F9KoCPTsMjJ5zLwe783N84DzZn8CqNrgNclOQvBA17T/ODyOqoBz28utOjbd7XiuceUS2IlpSVi3sxPoUp4f3b15Q5SU5MEhUQKBcL0oc85GvCQbkGksArViwd7R8PS3/mb9c7tI+ej+vu/PntJgckTojCg+bqMwjw8/qxsXfQW232Vla9+8p+mufZzz6jIyaTjGYhMkXiEsaUFVxBRM6KPJlbDc0zCltbj1bRAlLmGfTB03NhsLWtkx4CGRBR4/TC3J+TVixZkaYRV5BKbV+e/4MHfsb5pXjndNS9H+066ZznG5NATMo1gYwLQvTFJyTJPDH6iSKAVyyAiCSwYB4y/rXg9eT2RzIe8EbUrfr2GQ1w1MZdTALZVcwqCd1LL1WOnibLcZ5mfssKOh2/o9c32nZ2c75Ye9Chs7Hv9EORUMRxYElGgPjmkUJsPiynrx63p2uuIOdylRDxMNb6XLX8qP6Uk5NdULAM8f38Vu7pst79qmMTJwu4QV66f7WPxg8QF2RwyaL1evsd5/9FDSeP0ej/0MlTN3/IYGrnMWdWwFsKyGFBeHThaXYdf/3123SZvyaBnCvyvVbPeMGdH/qu9eGJV8gYXk36FAhN7iftLLmEkEDsnf0LjaHKrTbdRCjDDeb98GFuxX+DGo96p9NBD45a67+q1icxXkACJVlySZQ9CotxnACfseIq5r/EGZSwIY6hs9ftM0lYq0dpcljlRcKyfH94blK004OHIZGYBUUpjsPwwmOlrvZD34VJccuw/Zw4vkyT86pKnaZunLuGvdzrwXaautfmaQ6wLok/z/0VQPn4O1ebB5u+gGhB5Gr7y7Njjbd2214vIy4hI17erj1M01Mf8D/1qE0tb+IUhuY4+cJj4GMzqFaGdsQrp5O23/PKuRqcjh68n4vup1FvH4yttbacH9de5lxkj7/3nWXwOFuPecMqYznPxTvcqh6f4bdXvatE3pKQ7ia9fWZMrrGx1smf3TZqo5PPeNUvVA8frZwzxuOkXTMf6xvU2TsNWg02nZXutLI5dXXvfTTd6WDtMYcAbx9bfJ48xoklhNR4yk7d/D0Ip90zTcm2G/yl1nojc0XW3WnZPQOF1XY2yVbvbB33Di80bVt10JPaDj540ZfdpupYWw3uPXjo5tfUk81+UqeTnY3b+dXHwUcFSub5t8eZwhKKuiT0qYk41o569wx2b0e1G7XNhjiZsAt68j/9JySLer8JXRoMaR8MUdKG9Z6b22wawGBxuxwT6aO4LhljptihW3TPJdTPUvTtJX8s7cJmV0XBYK+vHAc2+zK9LboU337c9NWKRA6rmAW7mm3UEC1Imu/d/z+9Bkzzu5Uhitp4ipJgaP/y1+bVkTG6f9t3IWVI+nYFp2WfAk1xLMds/O4PL/2n/2ZYROeQ3V4bJAyhC4Y+eCIY7JkKGKPMKe6WpH06ni7+5S/0/ff/SyH/D50DRSADgzKfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x100 at 0x11BEA5470>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open('tmp/temp_img.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'game',\n",
       " 'began',\n",
       " 'development',\n",
       " 'in',\n",
       " '2010',\n",
       " ',',\n",
       " 'carrying',\n",
       " 'over',\n",
       " 'a',\n",
       " 'large',\n",
       " 'portion',\n",
       " 'of',\n",
       " 'the',\n",
       " '<TARGET>',\n",
       " 'done',\n",
       " 'on',\n",
       " 'Valkyria',\n",
       " 'Chronicles',\n",
       " 'II',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wiki[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattevanoff/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/mattevanoff/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.all_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9babee37171a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# TODO Update for user input!!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0msample_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m102\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-9babee37171a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(sample_index)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m#     pickle.dump(word_path_mapping, f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mword_path_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_path_mapping_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0mletter2idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletters_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9babee37171a>\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m\"\"\" Unpickle file \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dill/dill.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mpik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mpik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_main_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# point obj class to main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dill/dill.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'__builtin__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NoneType'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#XXX: special case: NoneType missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mStockUnpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.all_models'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "\n",
    "\n",
    "# TODO remove this \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# from .utils import unpickle\n",
    "# TODO Move to utils \n",
    "def unpickle(filename):\n",
    "    \"\"\" Unpickle file \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "# data_path = '../../data/raw/word_level'\n",
    "# meta_json_data_path = '../../data/preprocessed/meta.json'\n",
    "# word_level_meta_path = '../../data/preprocessed/word_level_meta.csv'\n",
    "# word_path_mapping_path = '../../data/processed/word_path_mapping.pkl'\n",
    "# X_path = '../../data/processed/X.npy'\n",
    "# y_path = '../../data/processed/y.npy'\n",
    "\n",
    "# X_wiki2_path = '../../data/processed/X_wiki2.npy'\n",
    "# y_wiki2_path = '../../data/processed/y_wiki2.npy'\n",
    "\n",
    "# bigram_model_path = '../../data/processed/ngram_models/bigram_likelihood_model.pkl'\n",
    "# trigram_model_path = '../../data/processed/ngram_models/trigram_likelihood_model.pkl'\n",
    "# letters_path = '../../data/processed/letters_map.pkl'\n",
    "\n",
    "\n",
    "# DATA_DIR = '../../../data'\n",
    "\n",
    "DATA_DIR = '../../data'\n",
    "# TODO move this \n",
    "data_path = os.path.join(DATA_DIR, 'raw/word_level')\n",
    "meta_json_data_path = os.path.join(DATA_DIR, 'preprocessed/meta.json')\n",
    "word_level_meta_path = os.path.join(DATA_DIR, 'preprocessed/word_level_meta.csv')\n",
    "word_path_mapping_path = os.path.join(DATA_DIR, 'processed/word_path_mapping.pkl')\n",
    "X_path = os.path.join(DATA_DIR, 'processed/X.npy')\n",
    "y_path = os.path.join(DATA_DIR, 'processed/y.npy')\n",
    "bigram_model_path = os.path.join(DATA_DIR, 'processed/ngram_models/bigram_likelihood_model.pkl')\n",
    "trigram_model_path = os.path.join(DATA_DIR, 'processed/ngram_models/trigram_likelihood_model.pkl')\n",
    "letters_path = os.path.join(DATA_DIR, 'processed/letters_map.pkl')\n",
    "\n",
    "\n",
    "\n",
    "def ngram_backoff_model(sample_index, X, y, trigram_model, bigram_model, OOV_token=0):\n",
    "    # get index and target word\n",
    "    index = int(y[sample_index][1][0])\n",
    "    target = X[sample_index][index]\n",
    "    # get previous word(s)\n",
    "    try:\n",
    "        prev_word = X[sample_index][index-1]\n",
    "    except:\n",
    "        prev_word = '<bos>'\n",
    "    try:\n",
    "        prev_prev_word = X[sample_index][index-2]\n",
    "    except:\n",
    "        prev_prev_word = '<bos>'\n",
    "    # model preds \n",
    "    pred = trigram_model[(prev_prev_word, prev_word)]\n",
    "    if pred == OOV_token:\n",
    "        pred = bigram_model[(prev_word)]\n",
    "        if pred == OOV_token:\n",
    "            pred = 'UNK'\n",
    "    return pred \n",
    "\n",
    "\n",
    "def teseract_baseline(sample_index, y, word_path_mapping, letters, tmpdir='tmp/'):\n",
    "    img_width = 256\n",
    "    img_height = 100\n",
    "    # gets image from sample index\n",
    "    img = word_path_mapping[y[sample_index][0]]\n",
    "    print(img)\n",
    "    im = Image.open(img)  # img is the path of the image \n",
    "    im = im.convert(\"RGBA\")\n",
    "    im = im.resize((img_width, img_height))\n",
    "    newimdata = []\n",
    "    datas = im.getdata()\n",
    "\n",
    "    vals = 255\n",
    "\n",
    "    for item in datas:\n",
    "        if item[0] < vals or item[1] < vals or item[2] < vals:\n",
    "            newimdata.append(item)\n",
    "        else:\n",
    "            newimdata.append((255, 255, 255))\n",
    "    im.putdata(newimdata)\n",
    "\n",
    "    im = im.filter(ImageFilter.MedianFilter())\n",
    "    enhancer = ImageEnhance.Contrast(im)\n",
    "    im = enhancer.enhance(2)\n",
    "    im = im.convert('1')\n",
    "    \n",
    "    if not os.path.exists(tmpdir):\n",
    "        os.makedirs(tmpdir)\n",
    "    save_img_path = os.path.join(tmpdir, 'temp_img.jpg')\n",
    "    im.save(save_img_path)\n",
    "    \n",
    "    text = pytesseract.image_to_string(Image.open(save_img_path),\n",
    "                config='-c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyz -psm 13', lang='eng')\n",
    "    \n",
    "    # os.remove(save_img_path)\n",
    "    # os.rmdir(tmpdir)\n",
    "    shutil.rmtree(tmpdir)\n",
    "    return text, len(text) \n",
    "\n",
    "\n",
    "    \n",
    "def get_ocr_model_pred(sample_index, y, word_path_mapping, letters):\n",
    "    ocr_pred, len_pred = teseract_baseline(sample_index, y, word_path_mapping, letters)\n",
    "    return ocr_pred, len_pred\n",
    "\n",
    "def get_language_model_pred(sample_index, X, y, trigram_model, bigram_model):\n",
    "    pred = ngram_backoff_model(sample_index, X, y, trigram_model, bigram_model)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def get_pos_tags(sample_index):\n",
    "    return []\n",
    "\n",
    "def weight_features(sample_index, X, y, trigram_model, bigram_model, word_path_mapping, letters, weights={}):\n",
    "    ocr_pred, len_pred = get_ocr_model_pred(sample_index, y, word_path_mapping, letters)\n",
    "    lm_pred = get_language_model_pred(sample_index, X, y, trigram_model, bigram_model)\n",
    "    pos_pred = get_pos_tags(sample_index)\n",
    "    \n",
    "    return ocr_pred, len_pred, lm_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def absoluteFilePaths(directory):\n",
    "    \"\"\"Walk filepaths\"\"\"\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            yield os.path.join(dirpath, f)\n",
    "\n",
    "def create_image_path(df, data_path, use_s3=False):\n",
    "    \"\"\"Create dictionary for mapping of word to data path\"\"\"\n",
    "    if use_s3:\n",
    "        [f.key for f in files[:5] if '.png' in f.key]\n",
    "    all_paths = [i for i in absoluteFilePaths(data_path)]\n",
    "    all_path_endings = [i.split('/')[-1].split('.')[0] for i in all_paths]\n",
    "    all_path_dict = defaultdict(lambda: 0, dict(zip(all_path_endings, all_paths)))\n",
    "    df['image_path'] = df['image_name'].map(lambda x: all_path_dict[x])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def main(sample_index):\n",
    "    \n",
    "\n",
    "    # dataset \n",
    "    X = list(np.load(X_path))\n",
    "    y = np.load(y_path)\n",
    "    # Language Models\n",
    "    bigram_model = unpickle(bigram_model_path)\n",
    "    trigram_model = unpickle(trigram_model_path)\n",
    "\n",
    "    # Meta\n",
    "    meta = pd.read_json(meta_json_data_path)\n",
    "    word_level_df = pd.read_csv(word_level_meta_path)\n",
    "    word_level_df = create_image_path(word_level_df, data_path)\n",
    "\n",
    "    # word_path_mapping = defaultdict(lambda: 0, dict(zip(word_level_df.token, word_level_df.image_path)))                              \n",
    "    # with open(os.path.join(DATA_DIR, 'processed', 'word_path_mapping.pkl'), 'wb') as f:\n",
    "    #     pickle.dump(word_path_mapping, f)\n",
    "\n",
    "    word_path_mapping = unpickle(word_path_mapping_path)\n",
    "    letter2idx = unpickle(letters_path)\n",
    "\n",
    "    letters = list(letter2idx.keys())\n",
    "    letters = ''.join(letters[1:-2])\n",
    "\n",
    "\n",
    "    ocr_pred, len_pred, lm_pred = weight_features(sample_index, X, y, trigram_model, bigram_model, word_path_mapping, letters)\n",
    "    return ocr_pred, len_pred, lm_pred\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # TODO Update for user input!!!!!\n",
    "    sample_index = 102\n",
    "    main(sample_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
