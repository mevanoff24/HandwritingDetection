{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-west2'\n",
    "\n",
    "import os\n",
    "os.environ['key'] = key\n",
    "os.environ['secret'] = secret\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_SERVER_PUBLIC_KEY = os.environ['key']\n",
    "\n",
    "AWS_SERVER_SECRET_KEY = os.environ['secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "\n",
    "\n",
    "# TODO remove this \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# from .utils import unpickle\n",
    "# TODO Move to utils \n",
    "def unpickle(filename):\n",
    "    \"\"\" Unpickle file \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "# DATA_DIR = '../../../data'\n",
    "\n",
    "DATA_DIR = '../../data'\n",
    "# TODO move this \n",
    "data_path = os.path.join(DATA_DIR, 'raw/word_level')\n",
    "meta_json_data_path = os.path.join(DATA_DIR, 'preprocessed/meta.json')\n",
    "word_level_meta_path = os.path.join(DATA_DIR, 'preprocessed/word_level_meta.csv')\n",
    "word_path_mapping_path = os.path.join(DATA_DIR, 'processed/word_path_mapping.pkl')\n",
    "X_path = os.path.join(DATA_DIR, 'processed/X.npy')\n",
    "y_path = os.path.join(DATA_DIR, 'processed/y.npy')\n",
    "bigram_model_path = os.path.join(DATA_DIR, 'processed/ngram_models/bigram_likelihood_model.pkl')\n",
    "trigram_model_path = os.path.join(DATA_DIR, 'processed/ngram_models/trigram_likelihood_model.pkl')\n",
    "letters_path = os.path.join(DATA_DIR, 'processed/letters_map.pkl')\n",
    "\n",
    "\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import dill as pickle\n",
    "\n",
    "\n",
    "# client = boto3.resource('s3')\n",
    "# bucket = client.Bucket('handwrittingdetection')\n",
    "\n",
    "# session = boto3.Session(\n",
    "#     aws_access_key_id=settings.AWS_SERVER_PUBLIC_KEY,\n",
    "#     aws_secret_access_key=settings.AWS_SERVER_SECRET_KEY,\n",
    "# )\n",
    "# client = session.resource('s3')\n",
    "\n",
    "# s3_client = boto3.client('s3', \n",
    "#                       aws_access_key_id=AWS_SERVER_PUBLIC_KEY, \n",
    "#                       aws_secret_access_key=AWS_SERVER_SECRET_KEY, \n",
    "#                       region_name='us-west2'\n",
    "#                       )\n",
    "\n",
    "\n",
    "def s3_init(bucketname='handwrittingdetection'):\n",
    "\n",
    "    \n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_SERVER_PUBLIC_KEY,\n",
    "        aws_secret_access_key=AWS_SERVER_SECRET_KEY,\n",
    "    )\n",
    "    \n",
    "    client = session.resource('s3')\n",
    "    bucket = client.Bucket(bucketname)\n",
    "    return client, bucket\n",
    "\n",
    "# client, bucket = s3_init(bucketname='handwrittingdetection')\n",
    "    \n",
    "def unpickle_s3(filename, client=None, bucket=None):\n",
    "    with BytesIO() as data:\n",
    "        bucket.download_fileobj(filename, data)\n",
    "        data.seek(0)\n",
    "        return pickle.load(data)\n",
    "\n",
    "\n",
    "def tokenize_and_join(context):\n",
    "    tokens = word_tokenize(context)\n",
    "    context = ' '.join(tokens)\n",
    "    return tokens, context\n",
    "\n",
    "def ngram_backoff_model(left_text, right_text, trigram_model, bigram_model, OOV_token=0):\n",
    "\n",
    "\n",
    "    left_tokens, left_text = tokenize_and_join(left_text)\n",
    "    right_tokens, right_text = tokenize_and_join(right_text)\n",
    "    full_text = left_text + ' [] '  + right_text\n",
    "\n",
    "    # get previous word(s)\n",
    "    try:\n",
    "        prev_word = left_tokens[-1]\n",
    "    except:\n",
    "        prev_word = '<bos>'\n",
    "    try:\n",
    "        prev_prev_word = left_tokens[-2]\n",
    "    except:\n",
    "        prev_prev_word = '<bos>'\n",
    "    # model preds \n",
    "#     print(prev_prev_word, prev_word)\n",
    "    pred = trigram_model[(prev_prev_word, prev_word)]\n",
    "#     print('pred1', pred)\n",
    "    if pred == OOV_token:\n",
    "        pred = bigram_model[(prev_word)]\n",
    "#         print('pred2', pred)\n",
    "        if pred == OOV_token:\n",
    "            pred = 'UNK'\n",
    "    return pred \n",
    "\n",
    "\n",
    "def teseract_baseline(file_url, word_path_mapping, letters, tmpdir='tmp/'):\n",
    "    img_width = 256\n",
    "    img_height = 100\n",
    "    # gets image from sample index\n",
    "    # img = word_path_mapping[y[sample_index][0]]\n",
    "    im = Image.open(file_url)  # img is the path of the image\n",
    "    im = im.convert(\"RGBA\")\n",
    "    im = im.resize((img_width, img_height))\n",
    "    newimdata = []\n",
    "    datas = im.getdata()\n",
    "\n",
    "    vals = 255\n",
    "\n",
    "    for item in datas:\n",
    "        if item[0] < vals or item[1] < vals or item[2] < vals:\n",
    "            newimdata.append(item)\n",
    "        else:\n",
    "            newimdata.append((255, 255, 255))\n",
    "    im.putdata(newimdata)\n",
    "\n",
    "    im = im.filter(ImageFilter.MedianFilter())\n",
    "    enhancer = ImageEnhance.Contrast(im)\n",
    "    im = enhancer.enhance(2)\n",
    "    im = im.convert('1')\n",
    "    \n",
    "    if not os.path.exists(tmpdir):\n",
    "        os.makedirs(tmpdir)\n",
    "    save_img_path = os.path.join(tmpdir, 'temp_img.jpg')\n",
    "    im.save(save_img_path)\n",
    "    \n",
    "    text = pytesseract.image_to_string(Image.open(save_img_path),\n",
    "                config='-c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyz -psm 13', lang='eng')\n",
    "    \n",
    "    # os.remove(save_img_path)\n",
    "    # os.rmdir(tmpdir)\n",
    "    # shutil.rmtree(tmpdir)\n",
    "    return text, len(text) \n",
    "\n",
    "\n",
    "    \n",
    "def get_ocr_model_pred(file_url, word_path_mapping, letters):\n",
    "    ocr_pred, len_pred = teseract_baseline(file_url, word_path_mapping, letters)\n",
    "    return ocr_pred, len_pred\n",
    "\n",
    "def get_language_model_pred(left_text, right_text, trigram_model, bigram_model):\n",
    "    pred = ngram_backoff_model(left_text, right_text, trigram_model, bigram_model)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def get_pos_tags(left_text, right_text):\n",
    "    return []\n",
    "\n",
    "def weight_features(left_text, right_text, file_url, trigram_model, bigram_model, word_path_mapping, letters, weights={}):\n",
    "    ocr_pred, len_pred = get_ocr_model_pred(file_url, word_path_mapping, letters)\n",
    "    print('OCR', ocr_pred, len_pred)\n",
    "    lm_pred = get_language_model_pred(left_text, right_text, trigram_model, bigram_model)\n",
    "    print('LM', lm_pred)\n",
    "    pos_pred = get_pos_tags(left_text, right_text)\n",
    "    \n",
    "    return ocr_pred, len_pred, lm_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def absoluteFilePaths(directory):\n",
    "    \"\"\"Walk filepaths\"\"\"\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            yield os.path.join(dirpath, f)\n",
    "\n",
    "\n",
    "def create_image_path(df, data_path, use_s3=False, s3_image_path='data/word_level'):\n",
    "    \"\"\"Create dictionary for mapping of word to data path\"\"\"\n",
    "    if use_s3:\n",
    "        files = list(bucket.objects.filter(Prefix='data/word_level/sample'))\n",
    "        all_paths = [f.key for f in files if '.png' in f.key]\n",
    "    else:\n",
    "        all_paths = [i for i in absoluteFilePaths(data_path)]\n",
    "        \n",
    "    all_path_dict = defaultdict(lambda: 0, dict(zip(all_path_endings, all_paths)))\n",
    "    all_path_endings = [i.split('/')[-1].split('.')[0] for i in all_paths]\n",
    "    defaultdict(lambda: 0, dict(zip(all_path_endings, all_paths)))\n",
    "    df['image_path'] = df['image_name'].map(lambda x: all_path_dict[x])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction(left_text, right_text, file_url, use_s3=False):\n",
    "\n",
    "    if use_s3:\n",
    "\n",
    "        client, bucket = s3_init(bucketname='handwrittingdetection')\n",
    "\n",
    "        bigram_model_path = 'data/ngram_models/bigram_likelihood_model.pkl'\n",
    "        trigram_model_path = 'data/ngram_models/trigram_likelihood_model.pkl'\n",
    "\n",
    "        word_path_mapping_path = 'data/word_path_mapping.pkl'\n",
    "        letters_path = 'data/letters_map.pkl'\n",
    "\n",
    "        bigram_model = unpickle_s3(bigram_model_path, client, bucket)\n",
    "        trigram_model = unpickle_s3(trigram_model_path, client, bucket)\n",
    "\n",
    "        word_path_mapping = unpickle_s3(word_path_mapping_path, client, bucket)\n",
    "        letter2idx = unpickle_s3(letters_path, client, bucket)\n",
    "\n",
    "\n",
    "    else:\n",
    "        data_path = os.path.join(DATA_DIR, 'raw/word_level')\n",
    "        meta_json_data_path = os.path.join(DATA_DIR, 'preprocessed/meta.json')\n",
    "        word_level_meta_path = os.path.join(DATA_DIR, 'preprocessed/word_level_meta.csv')\n",
    "        word_path_mapping_path = os.path.join(DATA_DIR, 'processed/word_path_mapping.pkl')\n",
    "        bigram_model_path = os.path.join(DATA_DIR, 'processed/ngram_models/bigram_likelihood_model.pkl')\n",
    "        trigram_model_path = os.path.join(DATA_DIR, 'processed/ngram_models/trigram_likelihood_model.pkl')\n",
    "        letters_path = os.path.join(DATA_DIR, 'processed/letters_map.pkl')\n",
    "\n",
    "        # Language Models\n",
    "        bigram_model = unpickle(bigram_model_path)\n",
    "        trigram_model = unpickle(trigram_model_path)\n",
    "\n",
    "        # Meta\n",
    "        meta = pd.read_json(meta_json_data_path)\n",
    "        word_level_df = pd.read_csv(word_level_meta_path)\n",
    "        word_level_df = create_image_path(word_level_df, data_path)\n",
    "\n",
    "        # word_path_mapping = defaultdict(lambda: 0, dict(zip(word_level_df.token, word_level_df.image_path)))                              \n",
    "        # with open(os.path.join(DATA_DIR, 'processed', 'word_path_mapping.pkl'), 'wb') as f:\n",
    "        #     pickle.dump(word_path_mapping, f)\n",
    "\n",
    "        word_path_mapping = unpickle(word_path_mapping_path)\n",
    "        letter2idx = unpickle(letters_path)\n",
    "\n",
    "    letters = list(letter2idx.keys())\n",
    "    letters = ''.join(letters[1:-2])\n",
    "\n",
    "    left_text = left_text.rstrip()\n",
    "    right_text = right_text.rstrip()\n",
    "\n",
    "    ocr_pred, len_pred, lm_pred = weight_features(left_text, right_text, file_url, trigram_model, bigram_model, word_path_mapping, letters)\n",
    "    return ocr_pred, len_pred, lm_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR wk 2\n",
      "dog ran\n",
      "pred1 0\n",
      "pred2 a\n",
      "LM a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('wk', 2, 'a')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_text = 'the dog ran'\n",
    "right_text = 'the house'\n",
    "file_path = '../../data/raw/word_level/a01/a01-007u/a01-007u-00-05.png'\n",
    "\n",
    "get_prediction(left_text, right_text, file_path, use_s3=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAABICAAAAAAvl2PSAAAUyklEQVR4nL16W49kx5HeFxGZ55yqrp7unp4Zzv0ickSOREviTbRIWpIFrATY8F4ebMMvfl4Y8B/xP/CLHwx4YRgLw+Qa3l1dLJmURUmUyCHF2yw5w7nfp+9VdU5mRoQfqqune6aH5kqw86FQOCczz5cRkRFfRCY5dm3/7ic+09Xjl/+8P7N7h//XjR/x/MIe0q7tllfy/1c491souz3Nl33Fud/6hVt7uzYGoq1XKTr5yprd/Wl++on5OFsZsTjtNsukfd67bU0ZwLauYddeMv/tTxNXUkbvH61roW3TB5S8fu6Nkq+Hq83Rb38JgDABcOyO4IvhgjywhN2BgXv93IYG4x+deDm409b0Xnz5g99eXS+SC43Wl57/2p5e3Hr50J+/V9sxiHa1Ietu/ei/bTSy0OVn/u3Cdju0tPzmT0Y2LCKRIbE5c/Qrh0JkOP1+aB7VdpcY9w58r/dfysxxu3Xn6my8Ly+19tLPOi9VCj2JSW3l7Ee3X9k3W4Me0tkfANRBj1AlmiMvfXrnu2fO/yxmz9UWLh1/8nMtcvhWqRwayAPSh8vf+3Kkh1H8IQKkR9kYOB74F/Vi3DMenpAwXTxJuvzqxTkeX/amKr2xBVCp1jeynJxlOAE02QR/qFbpUTYGGFlh8TyimcDTD6mu/PDHpfIN3X/6yM2b9yyIaxilucf+7NSMCmQK7PdpDyzmURIjcGRnQZTJCuDkyBfezI2B9/3j53rjz869rynWNfXk9t/88XGxiqbL/XtB2PriFwTmDAJquv+EqHtvKfcQe8++MB9mZk/NvTfUrCIpX3jtnxzppYYA0O8rsh1NHxWSpivY/g1PNy8yZxvJ/opjNZh/5lsLA2tTSsD5165o2DFyt+bAo3frjqgtAQBcH5KcPYxYsfLzi5EY/ceemg0m7EcWDv/mA2tgQXH99YVD/xdcTvR5ToR2uMLglNeWed+eB0bsNjxtnEcMYwnH9tbiSg01c4cO/yxIB8l6/q3ve/W5WqTJz+chwxbygPHSz271n/nmA/0fGm1kosM4yuRpv7iQGBhx37PduykWwNKHJ06H3S3ji1odAQaewOPbr/+ns7fW3l+nB5T80CCi7lqXUqcFhyJZVuFIFPa9/LUmVhYpXf4fl9vsgE/n8ftjvwisSXeeuACEX7y1pqzrl06HQMDuNuAT95SurrlXoMGCkBIZm5LHvc+NP/CeuunSuwv7RGDy+zlYgtOUH5Ly9VVoXl76u+XWN1/vgOTTZ+xlvBzQC9kZrkBhVYZmXnzlG7V1INYP30lWnHfb0V8Mmjs2JSe8PBpzv4w/NdHPG6PmmlekDsyqEkSTF5MYakKz+PUn6mBhRtNHtzrdUuB9y/AdRuKPtBkDba2HzahyyL1hYNjDa5iumhnBizRJQzXXUHDz4mCSCqF36MXHeszBbHgjwwg2lfMUwQMb/lGOTLdB5pksnrXbWE72SMtwgODjMlrfUIoze0LpYi+EigoQ2EL/wMuLlPKMDs/eUc1GDwD6POK9HXGkbcB80BqQ3eH2KBET3M2ttBpqpsRgFqkiAgOoI8f+qafJkoV88WzHbvToePJocO7Ynhuxh6QtCxenXbw9fDKAyEmYexWJYpSdidQJDHenor3BkyeDdYnKJ1c6fjj++sNGsvmCtmzuAZ/Cx0rfsjkylMy3b4BN+U0GmHvggWTK0IJixYTcQOQwBMbc872ZWj3mS0kftu4HRejbdU07IU3iKXgsXFfceLIgNtyezNHWDwAS+ODgWJMaGkfbJZu8JYQmojdz4mTdDGaq/MmN7DkDu+ykqc4+PxJsfpY/bfNIuxKZicIgPrI7kZdh0ORzMZGIkAKsPlkvU//gP31cJPTm9YoZx+0Zk02l5Lq5W7dEtFOyO7xK6EkyFxAMBv4cq2Xygij9UEbZeiWYQ6d0gcjCgTPXIh77xnKd6ggVUjMSJqdJlGJyku2CMnrAb+xEGUKTVWHd7PZ0e0dMUQgAuKB4W7VUjUd7rKYkRAS4txUTk4b5uj3w3cXrbSbzoAWUgpJHKcIOemDSXYoTO/O/0KUuKJe6KvaITF8m8NzDPFc5B8mZuEhvwq+IejACBT30zcvPnbCjpeewlkzHKQgFJepUZiZ7zz/Xj+z4emCdcRQpVpKITMVFxttRFrBboX7IXnPJOaoQQJMQ4oXIyaX/4jN9aqISSiqltB/fu5f3hsVBb0+cF67dMgW2L8Y0gOCJohGV9SBTyyfAO5dqG50EiDHazyqJbWYtMcC06QScBeQuMc4wQJTbPPrlht963wdrzM5yYO8fHZa+ByfRXNHE5KYiuN926iuM2YaZqRoI26bWzGx07trpJ6sdoyhT6HIyrpYL3FACZMJUHAAJxODkOY3OXdg4uwKHbuTYH3ZltbmxLx47vLBQzTcVIVOYupIJ0XrAM20CowIiD7wHzHBSgevw9gdv6t3H9k9ZuDEIiNV+8gxN4eLTVWA3KUJQgglN5y/ZVj78rytZPFWxdKHeaLkwrl2ztxfk4J6XHp+rEAyyI0TCtzu2KbU+eo2SSKTihdmFOo56+dXVdb62ujds7SUnN672Lq6ZDlbtpgcOZkJQZujmXMTFHet/9es1oXb+wEpmklIVVKyVJV3Re/Tpc987WPGWg/UHxbRNcHws+KAJHTlA7sXE29XffDZM4/U7KU+6GYHgXaGFZzlbG+XymnoxU5gxEYkDMLfC5N3HvxoNyMNX/vn3v3OIVQuEFb2aowTB6Bd/eXG93XKwW2Fllx0R1scUsvVx5ziZK4Sw8cZZdN5d/uB0NRAngpPDTSjbXniPSr5350CqrfLCEXAmAcBGEVru/HDdIHHw7ZNPlReup0Y+XarW7rQpMIcS2/De8PuPc2+qsoe9231g7MWLUexGoWKGc1p/867P+srwfNfPJiAwAYaQQdKMuSSmz47NZYYwyIkmdJi4gH340SViH/ZfOFGJnTrKXJ7Rcu+Hn2QV9X5umS/9z4UqBGXjXW1+y9LCYkzkttFPVKIDRUybEe/tcjVsLXhhC5PEX0D1jMlIuNhbzwyITaEkVKIbg+BEXsp5ryWRLYAoVNFrjYr5P3374/HGCrUeQ/Qb5x5TciV7VHViU2JrJI5G11edi3BGbm+tazcsTstX90SYOYujkIAItnG7HtRlJS/vCwKFMCHSZsjKgOdVkAUfv3dmJpDNJCZhqw/90bdXz/2EhgbTyq4ld9k1BPj9AhYF9OuOUsKSFRCAdPen15G7Quner483IhyQrY6eVNxgqmwF44tPwEBcGJsFWM/EKC5fujpuLYz/7pPZJgTUSSQVD/XszML+K2/fY68jIyjiLlgA4/t65cVRG2o3X89MrLld/+h9RUwb5PbBjWRa1J0BElbI3kOWN8ZVm96906WEpM5eDO7uzMKM5qv9rLXE8f++NHZmkGWqGWCZe/KZ5+ecS+larRsAPnUX9xm9bPENBy80o+zRCDkjJ+9u/QpZ242aqnr19Q1mKibscK6lLf050TZTGn/49tLYEjGRUukMlnxCmwb7nTqp87nXrnZQdVAZh0BKsbf41AkW8tA6dEJINxM1mrLWKVqAwJ0w60aNu2NG8ZUrvzw/dCrDUtfD9r23l7M7l7Fmdeeg8XS0zhNs6dVf3F5dWx9aymbFUmbTLhs3C89V0Jy9PffaB6trLSF5EwIoUJCNG26B4rM9S7ptNxK8YNNt0PS5B99wM6m9jDK69cvnzpoQxY46xHz3tcHTexqDBBjBQl2Oz7RoQZ3f/Iu3Dz15qD7Ykw5uEVSc3cl5/75zbGile+f2vz7WA4S1mDq0G306irHAD5FGLgHY8mEU/SHSGPp7xmOxhpY/7Zcbb19dM6s992PnRmzX//ZgTyJY4UrKHPc/tpyUhEpO7777i7nZpxf2yeye2XZmJqOxLjgWX7m3PopRUK6/se/JU/3oWTl1cbS28dmCj3SwuAeMUgFA8W2EBshhmxRDf+46tAnt8Me/o6W1MGiLWb+jViVK4hs/+pP9IjCQuCVIvVfJzAQK9aW13se9huv9+4fzh/jgIYwa6obN/EZtBGJ5i958aeFIvZG6a7f4apkdztc+/62n9sbpXn7Ak20y74kYQ//wpXXn0QYtDQ11qogWXjj53i+Hmr0nPvr1wZe1J6RsxnXX3TrPqmSokYqETNZ1VR7eqD/7rVWLvaVKyghD7q8qKrTcXLqyb0DLKl1MIut7y7B56dk+KDoKEzntrFxOKz0AgCAn31lOJFqcS5PK+uyTzz9D+xd+ervVxI7x/5r5yvweKhXcbLx0tjQZMCQlrZ0sMWmqikkxu5EtForeiqvKmIvnDlcb86bPEEL9tXBg/8le5VBXDpO6E2OblLaHzdA7Nr/a8JqDrW77C/bUD/ZXxC+Vv8pjn6k6uvmXLz7+5bmoxUyXz/42zHaJqHJ1hnrLhTQ4ISERWZMJ2ceh8wY5AGGA1llJUtSmfuIrx3qBo1csBWow31KlT0qJ2/Ua6oNP3Rl7E3Ili83p03RkgdXDwgs3f4qMpI0u/fi3X/3OcRpttNfff/uOFATqV7lQ6BWrDMyeHYKsQUalARQcoIpsVkQ5u3EvUdhY/NaRSmoWMyBQYQMBWSsiwE1APmXQE2DUvFy9s1TJwt6nDw9m+yE6mSsWv/nOGlZ5Vkl47Z1rLx5960JZ0iQew1yigSb0Bh2TkBK7eWMVEIbkuQfnzLEepDWyoffr1OpGkQ7XPmqqRZ3h6G5GtbkQHJFQGEowYt5e1Kax6Xjpwmd85mCoRZoSOaqad7defZ1WYm2lEszobO+mWZnBukrBRpqfvdtVe0/Ox6j3lvuwkKr+KlbbXvGgKFw/9/ihu7/5qF3nfiEyS3BQcyCcevbLgz67eAgmwZUYVACzyHBnkGPq0WitZ13pPGitkevSBYlKXlJ78d9fyR67Equqn5lKzJ0H/IODV98bjQazayM+/efzDVvXkZkMm166d7uau9DcqRcHFE8OIi1/fOfdix3VSJazqEcKtO/UyePH+jNUVbEEN4kEZDEL5JPMTmET30YZ3ooKKzwSeRZmeIbn1bN/c35Mmkn6vZEwS0xYOPrdvRf+w/p6tUc39Ni/OVMDTFkDQcbihhLqksmZOAblrlv++OdXOklWHNBgoNqqcOTAK0dme01ugrmj5ybuYGPfZJ2bGzTDjVWrFpU4GQAiM/Yyztd//kbXFiUjcczM7PuHMwsHoi/951+2NE/jMviT7w+kCm4aA7nDDcTkBjKTSAaXbnjvk9/0r14oxmRUgrhWVo3nDxx94vjcQkWBnSpQLMqMAKXNgreDKAOdcYkuJA6Cw5jUgM671Ws3f3V7udTF6MjJZ/cd7FlxH7/3H2/pTC+NByf+5ZNNDKAijWlMHaI7gkpwuECFPGctafXcf79ZWoayNS5t5eqQWO858eXZmYPzc+QkBSQWwFY5mJ1QhDoGkkcu5KIBpggEL+pkPOp0+fpb9RMrq913DlRVQzIuYss/enWpN6BxXPjBd+cqIRIiB0wyBIiqRMywQgZXZxuOrl8afnZuNRF1UsJcR+ZSXFHRzLF/9PWGanEBvGIRp4Ai7C6UNkXn5DBBISaHUbbAlrsiJedAOfbAZFoTtLTn/+J3oddf8/rJP/tSP4I8CmVEQQGxIgUS56zRYYWBTLml4eVPLuPKVWq9oULKwYoCzr0zR9gPVk0XmxMD1HV0LU0IFiiB4M6AE4xhYMCdoMxFW2FLSWIkci8lRhOz4dpf/7DrDdYz5s/8s+O1RKfo3jGJuBPQCVwYTkXhKrWpFlIMffnW61dvltaEYK7GIHPOUqUanG3w5KnbT3091RfuHjkud4/RWAiAbtZ5JgVn0+AAu3sCTHMTASMywEIpZfjGXy+FJg/HM/v+1fM9YafATqSOAAd1xAKGlWAgZSEUMqWWx5rvvb9yaeX2SglWgJBDxUOrLXhJCCD0j7W9axtz81j/TpjEq+k9kUlSTXFyEEYkZEEDCofAlq3qxiFyOb44HufYaB5f7ygyA4HImI2gRuyBADB5MNLiYgLnoNR4tXBSuzvLv20/CevLbUSxkbGi1A4YWRh+SISwdovqixNc0+yTNn9NKYABxEIlsqs4u4aSg0mIfPSb7bVcqD8uv3vhcBAmAYHc2ZNgYqPkiOaMqrNN79RzKh5rG8ylr66Pq7V30/zfftIxVCkkSNZGO3ZtOlZiPhWA++Rjiz5mQgmAEwVEckSQwrku3hBbWPjGO/WYK23yzQuPmTBLJiVyodoDnJ0I5CAVUK0wAzM5oomTG+qZWnTv8bIx+/r64sXrY0XnAeTqniXkYj23K2GLmW1nQ4FdS0CO5AwvogyjCpCOyVyauSduOAuM0qcvkBtbgEy2Taqs1AAcTiTuAoGUUhlA1BgomLNUJfSszMyfsXD3nVt3hzfWrOkNKyP21vHEK/33n5vkBCCUMDmUokmxwwRQ2CYHcOc4KbZRCdR6/9mPr6ZAFMNSO89BkD0SIQeuJ/WCaWY2WW8gZne4i5YAKyRBGKX4QdjcEc3Da1frqv9ht3KzmZXY/eAMfa8fpmR280+Ok7kEcIcHJ6BycYCNjKtCQqK5v+9O1w56SMtrC2ATjyAg0LbLLwTQpBLmzm5MIECFHVF0UusYKDT0HHb4GRZ9MbVthYg8V9V8Px9QcXJQ3JZGUaBJ2k4EwDlBysTLVYsv321zI8Ouu324VlAEZQiRE3acYRiDzHiiWXipqBiYIgATeHREM5hYgHqvmrfc9MGZcZ/dimNKISfG1gUBJpcOAHIiBLgYSK1478TTo+UUuInDfuUS4B6Niuyo1RtNKmcT920MYrgITQ4fBGzE4sFQApFpRs1W9QJYicL2DIpkSwkAIk+WzNPLJ8YAcVJluMye/rjL1ZztP9ELZgA5GA8c+GzWNFXgJGAjCGDsRpN6P8kkFlIEHP1eC7AEAH2UaZHK6aHDgc2CN9zJfFK7Y6NCShxiCsf23zt+6nE5sZ9aIScQjAF3znL/rIgAd3InGIg3T+PdImyzz2bZAgp2DyyAlwiAaHIbykzuX17b5j2cnDIgjOl1QDeoE6TLlz786mIYRCfWsLOGqs68ORyTwFsA90iTiwKThW67/OHmxATXgOkdDaf/A8E5Kd6pSD2vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=152x72 at 0x1115C9048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client, bucket = s3_init(bucketname='handwrittingdetection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = list(bucket.objects.filter(Prefix='models/language_model/model.param'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[s3.ObjectSummary(bucket_name='handwrittingdetection', key='models/language_model/model.param'),\n",
       " s3.ObjectSummary(bucket_name='handwrittingdetection', key='models/language_model/model.param.config.json'),\n",
       " s3.ObjectSummary(bucket_name='handwrittingdetection', key='models/language_model/model.param.optim')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "from models.context2vec.src.eval.mscc import mscc_evaluation\n",
    "from models.context2vec.src.core.nets import Context2vec\n",
    "from models.context2vec.src.util.args import parse_args\n",
    "from models.context2vec.src.util.batch import Dataset\n",
    "from models.context2vec.src.util.config import Config\n",
    "from models.context2vec.src.util.io import write_embedding, write_config, read_config, load_vocab\n",
    "device = 'cpu'\n",
    "# args = parse_args()\n",
    "modelfile = 'models/context2vec/models/model.param'\n",
    "# modelfile = model_file[0].key\n",
    "wordsfile = 'models/context2vec/models/embedding.vec'\n",
    "config_file = modelfile+'.config.json'\n",
    "config_dict = read_config(config_file)\n",
    "model = Context2vec(vocab_size=config_dict['vocab_size'],\n",
    "                    counter=[1]*config_dict['vocab_size'],\n",
    "                    word_embed_size=config_dict['word_embed_size'],\n",
    "                    hidden_size=config_dict['hidden_size'],\n",
    "                    n_layers=config_dict['n_layers'],\n",
    "                    bidirectional=config_dict['bidirectional'],\n",
    "                    use_mlp=config_dict['use_mlp'],\n",
    "                    dropout=config_dict['dropout'],\n",
    "                    pad_index=config_dict['pad_index'],\n",
    "                    device=device,\n",
    "                    inference=True).to(device)\n",
    "model.load_state_dict(torch.load(modelfile, map_location='cpu'))\n",
    "optimizer = optim.Adam(model.parameters(), lr=config_dict['learning_rate'])\n",
    "# optimizer.load_state_dict(torch.load(modelfile+'.optim'))\n",
    "itos, stoi = load_vocab(wordsfile)\n",
    "unk_token = config_dict['unk_token']\n",
    "bos_token = config_dict['bos_token']\n",
    "eos_token = config_dict['eos_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "from models.context2vec.src.eval.mscc import mscc_evaluation\n",
    "from models.context2vec.src.core.nets import Context2vec\n",
    "from models.context2vec.src.util.args import parse_args\n",
    "from models.context2vec.src.util.batch import Dataset\n",
    "from models.context2vec.src.util.config import Config\n",
    "from models.context2vec.src.util.io import write_embedding, write_config, read_config, load_vocab\n",
    "\n",
    "class Inference():\n",
    "    def __init__(self, modelfile, wordsfile, config_file, device='cpu'):\n",
    "        \n",
    "        # args = parse_args()\n",
    "        modelfile = 'models/context2vec/models/model.param'\n",
    "        # modelfile = model_file[0].key\n",
    "        wordsfile = 'models/context2vec/models/embedding.vec'\n",
    "        config_file = modelfile+'.config.json'\n",
    "        config_dict = read_config(config_file)\n",
    "        model = Context2vec(vocab_size=config_dict['vocab_size'],\n",
    "                            counter=[1]*config_dict['vocab_size'],\n",
    "                            word_embed_size=config_dict['word_embed_size'],\n",
    "                            hidden_size=config_dict['hidden_size'],\n",
    "                            n_layers=config_dict['n_layers'],\n",
    "                            bidirectional=config_dict['bidirectional'],\n",
    "                            use_mlp=config_dict['use_mlp'],\n",
    "                            dropout=config_dict['dropout'],\n",
    "                            pad_index=config_dict['pad_index'],\n",
    "                            device=device,\n",
    "                            inference=True).to(device)\n",
    "        model.load_state_dict(torch.load(modelfile, map_location='cpu'))\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=config_dict['learning_rate'])\n",
    "        # optimizer.load_state_dict(torch.load(modelfile+'.optim'))\n",
    "        itos, stoi = load_vocab(wordsfile)\n",
    "        unk_token = config_dict['unk_token']\n",
    "        bos_token = config_dict['bos_token']\n",
    "        eos_token = config_dict['eos_token']\n",
    "        \n",
    "        \n",
    "    def _return_split_sentence(self, sentence):\n",
    "        if ' ' not in sentence:\n",
    "            print('sentence should contain white space to split it into tokens')\n",
    "            raise SyntaxError\n",
    "        elif '[]' not in sentence:\n",
    "            print('sentence should contain `[]` that notes the target')\n",
    "            raise SyntaxError\n",
    "        else:\n",
    "            tokens = sentence.lower().strip().split()\n",
    "            target_pos = tokens.index('[]')\n",
    "            return tokens, target_pos\n",
    "        \n",
    "    def run_inference_by_user_input(self, sentence, model, itos, stoi, unk_token, bos_token, eos_token, device, topK=30):\n",
    "\n",
    "        # evaluation mode \n",
    "        model.eval()\n",
    "        # norm_weight\n",
    "        model.norm_embedding_weight(model.criterion.W)\n",
    "\n",
    "        tokens, target_pos = return_split_sentence(sentence)\n",
    "        tokens[target_pos] = unk_token\n",
    "        tokens = [bos_token] + tokens + [eos_token]\n",
    "        indexed_sentence = [stoi[token] if token in stoi else stoi[unk_token] for token in tokens]\n",
    "        input_tokens = \\\n",
    "            torch.tensor(indexed_sentence, dtype=torch.long, device=device).unsqueeze(0)\n",
    "        topv, topi = model.run_inference(input_tokens, target=None, target_pos=target_pos, k=topK)\n",
    "        output = []  \n",
    "        for value, key in zip(topv, topi):\n",
    "            output.append((value.item(), itos[key.item()]))\n",
    "            print(value.item(), itos[key.item()])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_by_user_input(sentence, \n",
    "                                model,\n",
    "                                itos,\n",
    "                                stoi,\n",
    "                                unk_token,\n",
    "                                bos_token,\n",
    "                                eos_token,\n",
    "                                device):\n",
    "\n",
    "    def return_split_sentence(sentence):\n",
    "        if ' ' not in sentence:\n",
    "            print('sentence should contain white space to split it into tokens')\n",
    "            raise SyntaxError\n",
    "        elif '[]' not in sentence:\n",
    "            print('sentence should contain `[]` that notes the target')\n",
    "            raise SyntaxError\n",
    "        else:\n",
    "            tokens = sentence.lower().strip().split()\n",
    "            target_pos = tokens.index('[]')\n",
    "            return tokens, target_pos\n",
    "\n",
    "    ''' \n",
    "    norm_weight\n",
    "    '''\n",
    "    # evaluation mode \n",
    "    model.eval()\n",
    "    \n",
    "    model.norm_embedding_weight(model.criterion.W)\n",
    "\n",
    "    tokens, target_pos = return_split_sentence(sentence)\n",
    "    tokens[target_pos] = unk_token\n",
    "    tokens = [bos_token] + tokens + [eos_token]\n",
    "    indexed_sentence = [stoi[token] if token in stoi else stoi[unk_token] for token in tokens]\n",
    "    input_tokens = torch.tensor(indexed_sentence, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    topv, topi = model.run_inference(input_tokens, target=None, target_pos=target_pos)\n",
    "    output = []  \n",
    "    for value, key in zip(topv, topi):\n",
    "        output.append((value.item(), itos[key.item()]))\n",
    "        print(value.item(), itos[key.item()])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = 'models/context2vec/models/model.param'\n",
    "wordsfile = 'models/context2vec/models/embedding.vec'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8051932454109192 into\n",
      "0.5680792927742004 above\n",
      "0.25667303800582886 through\n",
      "0.0 <PAD>\n",
      "0.0 <EOS>\n",
      "0.0 <BOS>\n",
      "-0.0033715590834617615 against\n",
      "-0.02418931946158409 across\n",
      "-0.09841619431972504 alongside\n",
      "-0.25158366560935974 from\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8051932454109192, 'into'),\n",
       " (0.5680792927742004, 'above'),\n",
       " (0.25667303800582886, 'through'),\n",
       " (0.0, '<PAD>'),\n",
       " (0.0, '<EOS>'),\n",
       " (0.0, '<BOS>'),\n",
       " (-0.0033715590834617615, 'against'),\n",
       " (-0.02418931946158409, 'across'),\n",
       " (-0.09841619431972504, 'alongside'),\n",
       " (-0.25158366560935974, 'from')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_text = 'the dog ran'\n",
    "right_text = 'the house'\n",
    "\n",
    "sentence = left_text + ' [] ' + right_text\n",
    "\n",
    "run_inference_by_user_input(sentence, model, itos, stoi, unk_token=unk_token, \n",
    "                            bos_token=bos_token, eos_token=eos_token, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.param             model.param.config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls models/context2vec/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py      run.py           \u001b[1m\u001b[34mtemplates\u001b[m\u001b[m/       \u001b[1m\u001b[34mtmp\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[34mmodels\u001b[m\u001b[m/          \u001b[1m\u001b[34mstatic\u001b[m\u001b[m/          test_pipe.ipynb  utils.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "from models.context2vec.src.eval.mscc import mscc_evaluation\n",
    "from models.context2vec.src.core.nets import Context2vec\n",
    "from models.context2vec.src.util.args import parse_args\n",
    "from models.context2vec.src.util.batch import Dataset\n",
    "from models.context2vec.src.util.config import Config\n",
    "from models.context2vec.src.util.io import write_embedding, write_config, read_config, load_vocab\n",
    "device = 'cpu'\n",
    "# args = parse_args()\n",
    "modelfile = 'models/context2vec/models/model.param'\n",
    "# modelfile = model_file[0].key\n",
    "wordsfile = 'models/context2vec/models/embedding.vec'\n",
    "config_file = modelfile+'.config.json'\n",
    "config_dict = read_config(config_file)\n",
    "model = Context2vec(vocab_size=config_dict['vocab_size'],\n",
    "                    counter=[1]*config_dict['vocab_size'],\n",
    "                    word_embed_size=config_dict['word_embed_size'],\n",
    "                    hidden_size=config_dict['hidden_size'],\n",
    "                    n_layers=config_dict['n_layers'],\n",
    "                    bidirectional=config_dict['bidirectional'],\n",
    "                    use_mlp=config_dict['use_mlp'],\n",
    "                    dropout=config_dict['dropout'],\n",
    "                    pad_index=config_dict['pad_index'],\n",
    "                    device=device,\n",
    "                    inference=True).to(device)\n",
    "model.load_state_dict(torch.load(modelfile, map_location='cpu'))\n",
    "optimizer = optim.Adam(model.parameters(), lr=config_dict['learning_rate'])\n",
    "# optimizer.load_state_dict(torch.load(modelfile+'.optim'))\n",
    "itos, stoi = load_vocab(wordsfile)\n",
    "unk_token = config_dict['unk_token']\n",
    "bos_token = config_dict['bos_token']\n",
    "eos_token = config_dict['eos_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_by_user_input(sentence, \n",
    "                                model,\n",
    "                                itos,\n",
    "                                stoi,\n",
    "                                unk_token,\n",
    "                                bos_token,\n",
    "                                eos_token,\n",
    "                                device):\n",
    "\n",
    "    def return_split_sentence(sentence):\n",
    "        if ' ' not in sentence:\n",
    "            print('sentence should contain white space to split it into tokens')\n",
    "            raise SyntaxError\n",
    "        elif '[]' not in sentence:\n",
    "            print('sentence should contain `[]` that notes the target')\n",
    "            raise SyntaxError\n",
    "        else:\n",
    "            tokens = sentence.lower().strip().split()\n",
    "            target_pos = tokens.index('[]')\n",
    "            return tokens, target_pos\n",
    "\n",
    "    ''' \n",
    "    norm_weight\n",
    "    '''\n",
    "    # evaluation mode \n",
    "    model.eval()\n",
    "    \n",
    "    model.norm_embedding_weight(model.criterion.W)\n",
    "\n",
    "    tokens, target_pos = return_split_sentence(sentence)\n",
    "    tokens[target_pos] = unk_token\n",
    "    tokens = [bos_token] + tokens + [eos_token]\n",
    "    indexed_sentence = [stoi[token] if token in stoi else stoi[unk_token] for token in tokens]\n",
    "    input_tokens = torch.tensor(indexed_sentence, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    topv, topi = model.run_inference(input_tokens, target=None, target_pos=target_pos)\n",
    "    output = []  \n",
    "    for value, key in zip(topv, topi):\n",
    "        output.append((value.item(), itos[key.item()]))\n",
    "        print(value.item(), itos[key.item()])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8051932454109192 into\n",
      "0.5680792927742004 above\n",
      "0.25667303800582886 through\n",
      "0.0 <PAD>\n",
      "0.0 <EOS>\n",
      "0.0 <BOS>\n",
      "-0.0033715590834617615 against\n",
      "-0.02418931946158409 across\n",
      "-0.09841619431972504 alongside\n",
      "-0.25158366560935974 from\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8051932454109192, 'into'),\n",
       " (0.5680792927742004, 'above'),\n",
       " (0.25667303800582886, 'through'),\n",
       " (0.0, '<PAD>'),\n",
       " (0.0, '<EOS>'),\n",
       " (0.0, '<BOS>'),\n",
       " (-0.0033715590834617615, 'against'),\n",
       " (-0.02418931946158409, 'across'),\n",
       " (-0.09841619431972504, 'alongside'),\n",
       " (-0.25158366560935974, 'from')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_text = 'the dog ran'\n",
    "right_text = 'the house'\n",
    "\n",
    "sentence = left_text + ' [] ' + right_text\n",
    "\n",
    "run_inference_by_user_input(sentence, model, itos, stoi, unk_token=unk_token, \n",
    "                            bos_token=bos_token, eos_token=eos_token, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattevanoff/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/mattevanoff/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:87: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x14c467358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "ocr_model_path = 'models/ocr/models/ocr_5_len.h5'\n",
    "\n",
    "\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# model = load_model(ocr_model_path, custom_objects={'ctc': ctc})\n",
    "model = load_model(ocr_model_path, custom_objects={'<lambda>': lambda y_true, y_pred: y_pred})\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 32, 1024)     1674240     dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 32, 1024)     4721664     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 80)       82000       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 80)       0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,488,608\n",
      "Trainable params: 6,488,608\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128)\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[node conv1/Conv2D/ReadVariableOp (defined at <ipython-input-4-2e47904da7de>:16)  = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1/kernel)]]\n\nCaused by op 'conv1/Conv2D/ReadVariableOp', defined at:\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-2e47904da7de>\", line 16, in <module>\n    model = load_model(ocr_model_path, custom_objects={'<lambda>': lambda y_true, y_pred: y_pred})\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 230, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 310, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\n    printable_module_name='layer')\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1302, in from_config\n    process_node(layer, node_data)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1260, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1258, in _dense_var_to_tensor\n    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1213, in _dense_var_to_tensor\n    return self.value()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 644, in value\n    return self._read_variable_op()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 727, in _read_variable_op\n    self._dtype)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 508, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[node conv1/Conv2D/ReadVariableOp (defined at <ipython-input-4-2e47904da7de>:16)  = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[{{node conv1/Conv2D/ReadVariableOp}} = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0eee3bf7f206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mnet_out_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnet_inp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_out_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mpred_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_out_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[node conv1/Conv2D/ReadVariableOp (defined at <ipython-input-4-2e47904da7de>:16)  = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1/kernel)]]\n\nCaused by op 'conv1/Conv2D/ReadVariableOp', defined at:\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-2e47904da7de>\", line 16, in <module>\n    model = load_model(ocr_model_path, custom_objects={'<lambda>': lambda y_true, y_pred: y_pred})\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 230, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 310, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\n    printable_module_name='layer')\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1302, in from_config\n    process_node(layer, node_data)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1260, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1258, in _dense_var_to_tensor\n    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1213, in _dense_var_to_tensor\n    return self.value()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 644, in value\n    return self._read_variable_op()\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 727, in _read_variable_op\n    self._dtype)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 508, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/Users/mattevanoff/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[node conv1/Conv2D/ReadVariableOp (defined at <ipython-input-4-2e47904da7de>:16)  = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "img_width = 128\n",
    "img_height = 64\n",
    "img_path = '../../data/raw/word_level/c03/c03-096f/c03-096f-03-05.png'\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "\n",
    "# sess = tf.Session()\n",
    "# K.set_session(sess)\n",
    "\n",
    "letters = [' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "def decode_batch(out):\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = ''\n",
    "        for c in out_best:\n",
    "            if c < len(letters):\n",
    "                outstr += letters[c]\n",
    "        ret.append(outstr)\n",
    "    return ret\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "# grayscale image\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# resize image\n",
    "img = cv2.resize(img, (img_width, img_height))\n",
    "# change image type\n",
    "img = img.astype(np.float32)\n",
    "# scale image \n",
    "img /= 255\n",
    "print(img.shape)\n",
    "img = img.reshape((1, img_width, img_height, 1))\n",
    "\n",
    "net_inp = model.get_layer(name='the_input').input\n",
    "net_out = model.get_layer(name='softmax').output\n",
    "\n",
    "X_data = img\n",
    "net_out_value = sess.run(net_out, feed_dict={net_inp: X_data})\n",
    "print(net_out_value)\n",
    "pred_texts = decode_batch(net_out_value)\n",
    "\n",
    "pred_texts\n",
    "# texts = []\n",
    "# for label in labels:\n",
    "#     text = ''.join(list(map(lambda x: letters[int(x)], label)))\n",
    "#     texts.append(text)\n",
    "    \n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
